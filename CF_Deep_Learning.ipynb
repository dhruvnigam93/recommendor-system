{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ef32e7-891a-492f-85d5-b09e3f43c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import mlfoundry as mlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af365507-0885-49b5-9736-cd55113fb7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c66ec6-439b-4f50-b67d-06f73fac4600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing API key at /home/ec2-user/.mlfoundry/credentials.netrc\n"
     ]
    }
   ],
   "source": [
    "mlf.login(api_key=\"OGQ1NDI4ZGMtZGY3My00ZWEyLTg2NGMtZjA3OTQzNDkzZDRiOmZjNjc4Mw==\", relogin=True)\n",
    "client = mlf.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0f89d-f414-484d-a75b-faea224d4ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e23e69-63a9-4b22-a8cc-170aeb41b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, mean_rating=3.58):\n",
    "        self.df = df\n",
    "        self.mean_rating = mean_rating\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        x = torch.tensor([row.user_id, row.movie_id], dtype=torch.int32)\n",
    "        y = torch.tensor(row.rating - self.mean_rating, dtype=torch.float)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64ab052-4493-4dbd-836d-ba3774cfa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/ml1m_train.csv\")\n",
    "train_dataset = MovieLensDataset(train)\n",
    "test = pd.read_csv(\"data/ml1m_test.csv\")\n",
    "test_dataset = MovieLensDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735de0b-c71b-494c-988d-d55d2e297c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80acbd3d-ae43-4ca3-b841-b127e5fc39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.user_biases = torch.nn.Embedding(n_users, 1)\n",
    "        self.item_biases = torch.nn.Embedding(n_items,1)\n",
    "        torch.nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "        self.user_biases.weight.data.fill_(0.)\n",
    "        self.item_biases.weight.data.fill_(0.)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = self.user_biases(user) + self.item_biases(item)\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1, keepdim=True)\n",
    "        return pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef79291b-6dac-42af-8c29-c80e437bc446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to the dashboard for the run: https://app.truefoundry.com/mlfoundry/176/85f1694846d3432490623e444b76066f/\n"
     ]
    }
   ],
   "source": [
    "run = client.get_run(\"cloud/recommendation-system/matrix-factorization-factor5-45\")\n",
    "mf_model = run.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098329dd-256c-476d-a005-e7ad74c8467d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f55d8802-3a10-4581-999e-30f7949d4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, mf: MatrixFactorization, e_factors, layer_size, n_users, n_items):\n",
    "        super().__init__()\n",
    "        self.mf = mf\n",
    "        self.mf.user_factors.weight.requires_grad = False\n",
    "        self.mf.user_biases.weight.requires_grad = False\n",
    "        self.mf.item_factors.weight.requires_grad = False\n",
    "        self.mf.item_biases.weight.requires_grad = False\n",
    "        \n",
    "        self.user_extra_factors = torch.nn.Embedding(n_users, e_factors)\n",
    "        self.item_extra_factors = torch.nn.Embedding(n_items, e_factors)\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(12 + 2 * e_factors, layer_size)\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        self.linear2 = torch.nn.Linear(layer_size, 1)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.user_extra_factors.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.item_extra_factors.weight)\n",
    "        self.user_extra_factors.weight.data.fill_(0.)\n",
    "        self.item_extra_factors.weight.data.fill_(0.)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        self.linear1.bias.data.fill_(0.01)\n",
    "        torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        self.linear2.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        joint_embed = torch.cat((self.mf.user_biases(user),\n",
    "                                 self.mf.user_factors(user),\n",
    "                                 self.mf.item_biases(item),\n",
    "                                 self.mf.item_factors(item),\n",
    "                                 self.user_extra_factors(user),\n",
    "                                 self.item_extra_factors(item)), dim=1)\n",
    "        output = self.linear1(joint_embed)\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear2(output)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec2cf9-0a9b-4ced-bcc3-3356dea22b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78acaa0a-0dee-472b-a918-83b733ccfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers = 6041\n",
    "books = 3953\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d14b1f-bc81-4100-9202-0bb4986be961",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25b060-68b3-4079-8666-98480fbc87a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6313f15-607f-475d-a4e2-5a86b01300d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_batch, label_batch, loss_func, optimizer):\n",
    "    prediction = model(train_batch[:,0].to(device), train_batch[:,1].to(device))\n",
    "    loss = loss_func(prediction, label_batch.to(device))    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eee3216-6817-484c-b398-4a8117fe27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e_factors, layer_size, learning_rate=0.02):\n",
    "    run = client.create_run(project_name=\"recommendation-system\", run_name=f\"deep-factorization-2-layer\", log_system_metrics=False)\n",
    "    run.log_params({\"learning_rate\": learning_rate})\n",
    "    run.set_tags({\"type\": \"deep\"})\n",
    "    \n",
    "    model = DeepFactorization(mf_model, e_factors, layer_size, reviewers, books)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    model.to(device)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    epoches = 100\n",
    "    last_test_loss = 10000\n",
    "    for epoch in range(0, epoches):\n",
    "        # Training\n",
    "        pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        train_count = 1\n",
    "        train_loss = 0.\n",
    "        for i, (train_batch, label_batch) in pbar:\n",
    "            loss = train_loop(model, train_batch, label_batch, loss_func, optimizer)\n",
    "            train_loss += loss\n",
    "            train_count += 1\n",
    "            pbar.set_description(f'Train loss at {epoch} batch {i}: {train_loss/train_count}')\n",
    "\n",
    "        # Calculate test loss\n",
    "        pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "        test_loss = 0.\n",
    "        test_count = 1\n",
    "        for i,( test_batch, label_batch) in pbar:\n",
    "            with torch.no_grad():\n",
    "                prediction = model(test_batch[:,0].to(device), test_batch[:,1].to(device))\n",
    "                loss = loss_func(prediction, label_batch.to(device))\n",
    "                test_loss += loss.item()\n",
    "                test_count += 1\n",
    "                pbar.set_description(f'Test loss at {epoch} batch {i}: {test_loss/test_count}')\n",
    "        \n",
    "        run.log_metrics(\n",
    "            metric_dict={\n",
    "                \"train_loss\": train_loss/train_count,\n",
    "                \"test_loss\": test_loss/test_count,\n",
    "            }, step=epoch\n",
    "        )\n",
    "        # Early stopping\n",
    "        current_test_loss = test_loss/test_count\n",
    "        if last_test_loss - current_test_loss < 0.001:\n",
    "            print(f\"Stopping Training. Last\")\n",
    "            break\n",
    "        last_test_loss = current_test_loss\n",
    "    run.log_model(model=model, framework=\"pytorch\")\n",
    "    run.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df417ff6-49fc-436b-a2ab-c026e2669295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "369ba637-df42-438f-9351-ca14df413bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to the dashboard for the run: https://app.truefoundry.com/mlfoundry/176/09c234477f9f4be6995becb8ef4587f1/\n",
      "[mlfoundry] 2022-07-07T09:34:20+0000 WARNING failed to log git info because git repository is not present\n",
      "[mlfoundry] 2022-07-07T09:34:20+0000 INFO Run 'cloud/recommendation-system/deep-factorization-2-layer-82' has started.\n",
      "[mlfoundry] 2022-07-07T09:34:20+0000 INFO Parameters logged successfully\n",
      "[mlfoundry] 2022-07-07T09:34:20+0000 INFO Tags set successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 0 batch 6251: 0.8424707751607353: 100%|██████████| 6252/6252 [01:40<00:00, 62.10it/s]\n",
      "Test loss at 0 batch 1562: 0.8297074876554177: 100%|██████████| 1563/1563 [00:23<00:00, 65.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-07T09:36:25+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 1 batch 6251: 0.8308989784011417: 100%|██████████| 6252/6252 [01:41<00:00, 61.56it/s]\n",
      "Test loss at 1 batch 1562: 0.8289621773430759: 100%|██████████| 1563/1563 [00:23<00:00, 65.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-07T09:38:30+0000 INFO Metrics logged successfully\n",
      "Stopping Training. Last\n",
      "[mlfoundry] 2022-07-07T09:38:33+0000 INFO Model logged successfully\n",
      "Link to the dashboard for the run: https://app.truefoundry.com/mlfoundry/176/09c234477f9f4be6995becb8ef4587f1/\n"
     ]
    }
   ],
   "source": [
    "train(e_factors=3, layer_size=10, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31698a4d-e075-4774-8a17-8a9fbb303b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
