{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38fb603-cf87-4ac0-8b5a-18136847b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import mlfoundry as mlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c842316-342c-4eb9-adcd-3d4b0ba993e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7366b452-3741-4838-9e9f-aefc7dc7102e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing API key at /home/ec2-user/.mlfoundry/credentials.netrc\n"
     ]
    }
   ],
   "source": [
    "mlf.login(api_key=\"OGQ1NDI4ZGMtZGY3My00ZWEyLTg2NGMtZjA3OTQzNDkzZDRiOmZjNjc4Mw==\", relogin=True)\n",
    "client = mlf.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbfcc5-d539-493b-836c-1df957da7010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e4e454-fd77-44c5-b8b0-70cc464ed7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, mean_rating=3.58):\n",
    "        self.df = df\n",
    "        self.mean_rating = mean_rating\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        x = torch.tensor([row.user_id, row.movie_id], dtype=torch.int32)\n",
    "        y = torch.tensor(row.rating - self.mean_rating, dtype=torch.float)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b5d18f-11a3-4957-b541-aa9d1864b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/ml1m_train.csv\")\n",
    "train_dataset = MovieLensDataset(train)\n",
    "test = pd.read_csv(\"data/ml1m_test.csv\")\n",
    "test_dataset = MovieLensDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25245ce0-b7b6-4314-8d5e-4d3f3e4df29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658b5fc-89a2-48ad-9da6-982331beaa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbedb6c-ac1b-4dda-be14-58f266e32d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.user_biases = torch.nn.Embedding(n_users, 1)\n",
    "        self.item_biases = torch.nn.Embedding(n_items,1)\n",
    "        torch.nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "        self.user_biases.weight.data.fill_(0.)\n",
    "        self.item_biases.weight.data.fill_(0.)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = self.user_biases(user) + self.item_biases(item)\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1, keepdim=True)\n",
    "        return pred.squeeze()\n",
    "    \n",
    "    def freeze_users(self):\n",
    "        self.user_factors.weight.requires_grad = False\n",
    "        self.user_biases.weight.requires_grad = False\n",
    "        self.item_factors.weight.requires_grad = True\n",
    "        self.item_biases.weight.requires_grad = True\n",
    "        \n",
    "    def freeze_items(self):\n",
    "        self.user_factors.weight.requires_grad = True\n",
    "        self.user_biases.weight.requires_grad = True\n",
    "        self.item_factors.weight.requires_grad = False\n",
    "        self.item_biases.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c110f7ca-5832-4a25-8584-1a16524dce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers = 6041\n",
    "books = 3953\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a9bb75-9b2a-4412-a3d1-dba8fdaf4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8b69c-ed92-4992-a0bf-076e0885b415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677df065-ca2a-4110-835c-8fdc6beceb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_batch, label_batch, loss_func, optimizer):\n",
    "    # First pass with users layer freeze\n",
    "    model.freeze_users()\n",
    "    prediction = model(train_batch[:,0].to(device), train_batch[:,1].to(device))\n",
    "    loss = loss_func(prediction, label_batch.to(device))    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # First pass with items layer freeze\n",
    "    model.freeze_items()\n",
    "    prediction = model(train_batch[:,0].to(device), train_batch[:,1].to(device))\n",
    "    loss = loss_func(prediction, label_batch.to(device))    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336d7b66-9d89-4ccd-9173-62e4ec0a26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nfactor, learning_rate=0.02, weight_decay=1e-5):\n",
    "    run = client.create_run(project_name=\"recommendation-system\", run_name=f\"matrix-factorization-factor{nfactor}\", log_system_metrics=False)\n",
    "    run.log_params({\"nfactor\": nfactor, \"learning_rate\": learning_rate, \"weight_decay\": weight_decay})\n",
    "    \n",
    "    model = MatrixFactorization(reviewers, books, n_factors=nfactor)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    model.to(device)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    epoches = 100\n",
    "    last_test_loss = 10000\n",
    "    for epoch in range(0, epoches):\n",
    "        # Training\n",
    "        pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        train_count = 1\n",
    "        train_loss = 0.\n",
    "        for i, (train_batch, label_batch) in pbar:\n",
    "            loss = train_loop(model, train_batch, label_batch, loss_func, optimizer)\n",
    "            train_loss += loss\n",
    "            train_count += 1\n",
    "            pbar.set_description(f'Train loss at {epoch} batch {i}: {train_loss/train_count}')\n",
    "\n",
    "        # Calculate test loss\n",
    "        pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "        test_loss = 0.\n",
    "        test_count = 1\n",
    "        for i,( test_batch, label_batch) in pbar:\n",
    "            with torch.no_grad():\n",
    "                prediction = model(test_batch[:,0].to(device), test_batch[:,1].to(device))\n",
    "                loss = loss_func(prediction, label_batch.to(device))\n",
    "                test_loss += loss.item()\n",
    "                test_count += 1\n",
    "                pbar.set_description(f'Test loss at {epoch} batch {i}: {test_loss/test_count}')\n",
    "        \n",
    "        run.log_metrics(\n",
    "            metric_dict={\n",
    "                \"train_loss\": train_loss/train_count,\n",
    "                \"test_loss\": test_loss/test_count,\n",
    "            }, step=epoch\n",
    "        )\n",
    "        # Early stopping\n",
    "        current_test_loss = test_loss/test_count\n",
    "        if last_test_loss - current_test_loss < 0.01:\n",
    "            print(f\"Stopping Training. Last\")\n",
    "            break\n",
    "        last_test_loss = current_test_loss\n",
    "    run.log_model(model=model, framework=\"pytorch\")\n",
    "    run.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b51cf1-787b-4ccc-aa68-8f7627510d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860b862-2e14-4793-be9b-bc99f523e17d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to the dashboard for the run: https://app.truefoundry.com/mlfoundry/176/d020293a02f64a9ba70ff2da20679771/\n",
      "[mlfoundry] 2022-07-06T18:07:07+0000 WARNING failed to log git info because git repository is not present\n",
      "[mlfoundry] 2022-07-06T18:07:07+0000 INFO Run 'cloud/recommendation-system/matrix-factorization-factor10-24' has started.\n",
      "[mlfoundry] 2022-07-06T18:07:07+0000 INFO Parameters logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 0 batch 3125: 1.2143582426056834: 100%|██████████| 3126/3126 [02:12<00:00, 23.66it/s]\n",
      "Test loss at 0 batch 326: 1.177852744918044:  42%|████▏     | 327/782 [00:12<00:17, 25.89it/s] "
     ]
    }
   ],
   "source": [
    "train(nfactor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb44ce-7e80-4375-b073-4fc3cf5d2ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c41e45-bc79-40e6-8e7b-2e0d6392e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [20, 30, 50, 75, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73ed4523-cb43-4611-8bfd-05f40f154349",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to the dashboard for the run: https://app.truefoundry.com/mlfoundry/176/598dc4792eb845f0844b3a6221acb09a/\n",
      "[mlfoundry] 2022-07-06T15:07:58+0000 WARNING failed to log git info because git repository is not present\n",
      "[mlfoundry] 2022-07-06T15:07:58+0000 INFO Run 'cloud/recommendation-system/matrix-factorization-factor20-18' has started.\n",
      "[mlfoundry] 2022-07-06T15:07:58+0000 INFO Parameters logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 0 batch 3125: 12.23497039653411: 100%|██████████| 3126/3126 [02:02<00:00, 25.42it/s] \n",
      "Test loss at 0 batch 781: 10.590846121387312: 100%|██████████| 782/782 [00:28<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:10:30+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 1 batch 3125: 9.378546677117612: 100%|██████████| 3126/3126 [02:05<00:00, 24.86it/s] \n",
      "Test loss at 1 batch 781: 8.263826126035298: 100%|██████████| 782/782 [00:28<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:13:04+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 2 batch 3125: 7.421100911371312: 100%|██████████| 3126/3126 [02:01<00:00, 25.65it/s] \n",
      "Test loss at 2 batch 781: 6.647035461123724: 100%|██████████| 782/782 [00:29<00:00, 26.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:15:35+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 3 batch 3125: 6.046207107443911: 100%|██████████| 3126/3126 [02:02<00:00, 25.42it/s] \n",
      "Test loss at 3 batch 781: 5.49690130265432: 100%|██████████| 782/782 [00:28<00:00, 27.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:18:06+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 4 batch 3125: 5.058332944244175: 100%|██████████| 3126/3126 [02:00<00:00, 25.86it/s] \n",
      "Test loss at 4 batch 781: 4.660611960166259: 100%|██████████| 782/782 [00:28<00:00, 27.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:20:35+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 5 batch 3125: 4.332955695815006: 100%|██████████| 3126/3126 [02:01<00:00, 25.73it/s] \n",
      "Test loss at 5 batch 781: 4.039704348392413: 100%|██████████| 782/782 [00:29<00:00, 26.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:23:06+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 6 batch 3125: 3.7896791221922412: 100%|██████████| 3126/3126 [02:02<00:00, 25.57it/s]\n",
      "Test loss at 6 batch 781: 3.5696322646938827: 100%|██████████| 782/782 [00:28<00:00, 27.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:25:36+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 7 batch 3125: 3.3747653916959455: 100%|██████████| 3126/3126 [02:02<00:00, 25.56it/s]\n",
      "Test loss at 7 batch 781: 3.207180341998279: 100%|██████████| 782/782 [00:28<00:00, 27.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:28:07+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 8 batch 3125: 3.052206049111845: 100%|██████████| 3126/3126 [02:01<00:00, 25.69it/s] \n",
      "Test loss at 8 batch 781: 2.922692971820271: 100%|██████████| 782/782 [00:28<00:00, 27.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:30:38+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 9 batch 3125: 2.797150493392481: 100%|██████████| 3126/3126 [02:01<00:00, 25.67it/s] \n",
      "Test loss at 9 batch 781: 2.6956535396600287: 100%|██████████| 782/782 [00:28<00:00, 27.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:33:08+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 10 batch 3125: 2.592014936467577: 100%|██████████| 3126/3126 [02:03<00:00, 25.28it/s] \n",
      "Test loss at 10 batch 781: 2.5115734623462: 100%|██████████| 782/782 [00:29<00:00, 26.73it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:35:41+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 11 batch 3125: 2.424622912242232: 100%|██████████| 3126/3126 [02:04<00:00, 25.06it/s] \n",
      "Test loss at 11 batch 781: 2.3600922462127216: 100%|██████████| 782/782 [00:28<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:38:15+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 12 batch 3125: 2.2859973127482833: 100%|██████████| 3126/3126 [02:04<00:00, 25.19it/s]\n",
      "Test loss at 12 batch 781: 2.233689974246506: 100%|██████████| 782/782 [00:28<00:00, 27.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:40:48+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 13 batch 3125: 2.1694996009286234: 100%|██████████| 3126/3126 [02:05<00:00, 24.84it/s]\n",
      "Test loss at 13 batch 781: 2.126859411273727: 100%|██████████| 782/782 [00:29<00:00, 26.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:43:23+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 14 batch 3125: 2.0706152291125597: 100%|██████████| 3126/3126 [02:02<00:00, 25.61it/s]\n",
      "Test loss at 14 batch 781: 2.0354661965887817: 100%|██████████| 782/782 [00:28<00:00, 27.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:45:53+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 15 batch 3125: 1.9856043415097029: 100%|██████████| 3126/3126 [02:03<00:00, 25.39it/s]\n",
      "Test loss at 15 batch 781: 1.9564168651137468: 100%|██████████| 782/782 [00:28<00:00, 27.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:48:25+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 16 batch 3125: 1.9117161223863237: 100%|██████████| 3126/3126 [02:02<00:00, 25.59it/s]\n",
      "Test loss at 16 batch 781: 1.8873807236000344: 100%|██████████| 782/782 [00:28<00:00, 27.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:50:56+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 17 batch 3125: 1.84686417231973: 100%|██████████| 3126/3126 [02:03<00:00, 25.35it/s]  \n",
      "Test loss at 17 batch 781: 1.8265298644549393: 100%|██████████| 782/782 [00:28<00:00, 27.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:53:28+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 18 batch 3125: 1.789563599050636: 100%|██████████| 3126/3126 [02:02<00:00, 25.52it/s] \n",
      "Test loss at 18 batch 781: 1.7724595336317255: 100%|██████████| 782/782 [00:27<00:00, 28.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:55:58+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 19 batch 3125: 1.738429299360043: 100%|██████████| 3126/3126 [02:03<00:00, 25.41it/s] \n",
      "Test loss at 19 batch 781: 1.7240610043512299: 100%|██████████| 782/782 [00:28<00:00, 27.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T15:58:30+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 20 batch 3125: 1.6925289239371055: 100%|██████████| 3126/3126 [02:02<00:00, 25.56it/s]\n",
      "Test loss at 20 batch 781: 1.6804524964604188: 100%|██████████| 782/782 [00:27<00:00, 27.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:01:00+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 21 batch 3125: 1.6510268877137382: 100%|██████████| 3126/3126 [02:03<00:00, 25.38it/s]\n",
      "Test loss at 21 batch 781: 1.6409308449061895: 100%|██████████| 782/782 [00:29<00:00, 26.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:03:33+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 22 batch 3125: 1.613388989236281: 100%|██████████| 3126/3126 [02:04<00:00, 25.19it/s] \n",
      "Test loss at 22 batch 781: 1.6049170524528962: 100%|██████████| 782/782 [00:28<00:00, 27.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:06:05+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 23 batch 3125: 1.5789303799044563: 100%|██████████| 3126/3126 [02:03<00:00, 25.28it/s]\n",
      "Test loss at 23 batch 781: 1.5719459731307828: 100%|██████████| 782/782 [00:28<00:00, 27.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:08:37+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 24 batch 3125: 1.5473615701945018: 100%|██████████| 3126/3126 [02:01<00:00, 25.79it/s]\n",
      "Test loss at 24 batch 781: 1.5416236793096647: 100%|██████████| 782/782 [00:28<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:11:07+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 25 batch 3125: 1.5182728893961965: 100%|██████████| 3126/3126 [02:03<00:00, 25.39it/s]\n",
      "Test loss at 25 batch 781: 1.5136281734529888: 100%|██████████| 782/782 [00:27<00:00, 28.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:13:38+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 26 batch 3125: 1.4913164132465597: 100%|██████████| 3126/3126 [02:03<00:00, 25.32it/s]\n",
      "Test loss at 26 batch 781: 1.4876954407832024: 100%|██████████| 782/782 [00:29<00:00, 26.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:16:11+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 27 batch 3125: 1.4663476473155934: 100%|██████████| 3126/3126 [02:03<00:00, 25.28it/s]\n",
      "Test loss at 27 batch 781: 1.4635897987494828: 100%|██████████| 782/782 [00:29<00:00, 26.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:18:44+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 28 batch 3125: 1.4431114537974383: 100%|██████████| 3126/3126 [02:05<00:00, 24.93it/s]\n",
      "Test loss at 28 batch 781: 1.4411189294257232: 100%|██████████| 782/782 [00:27<00:00, 27.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:21:17+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 29 batch 3125: 1.4214045164834435: 100%|██████████| 3126/3126 [02:04<00:00, 25.17it/s]\n",
      "Test loss at 29 batch 781: 1.4201198166205355: 100%|██████████| 782/782 [00:28<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:23:50+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 30 batch 3125: 1.4010744154701074: 100%|██████████| 3126/3126 [02:03<00:00, 25.30it/s]\n",
      "Test loss at 30 batch 781: 1.4004413439091747: 100%|██████████| 782/782 [00:30<00:00, 25.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:26:23+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 31 batch 3125: 1.3819942253254305: 100%|██████████| 3126/3126 [02:02<00:00, 25.42it/s]\n",
      "Test loss at 31 batch 781: 1.381963987155588: 100%|██████████| 782/782 [00:28<00:00, 27.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:28:55+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 32 batch 3125: 1.3640649757867123: 100%|██████████| 3126/3126 [02:02<00:00, 25.60it/s]\n",
      "Test loss at 32 batch 781: 1.3645792114019089: 100%|██████████| 782/782 [00:29<00:00, 26.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:31:26+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 33 batch 3125: 1.3472090615873944: 100%|██████████| 3126/3126 [02:05<00:00, 24.83it/s]\n",
      "Test loss at 33 batch 781: 1.3481855482281702: 100%|██████████| 782/782 [00:28<00:00, 27.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:34:00+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 34 batch 3125: 1.3312590485721645: 100%|██████████| 3126/3126 [02:01<00:00, 25.67it/s]\n",
      "Test loss at 34 batch 781: 1.3327015028602776: 100%|██████████| 782/782 [00:28<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:36:31+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 35 batch 3125: 1.3162070331308153: 100%|██████████| 3126/3126 [02:04<00:00, 25.19it/s]\n",
      "Test loss at 35 batch 781: 1.3180517334286432: 100%|██████████| 782/782 [00:28<00:00, 27.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:39:04+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 36 batch 3125: 1.3019436630418897: 100%|██████████| 3126/3126 [02:02<00:00, 25.54it/s]\n",
      "Test loss at 36 batch 781: 1.3041660321322133: 100%|██████████| 782/782 [00:27<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:41:34+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 37 batch 3125: 1.2883682343423806: 100%|██████████| 3126/3126 [02:03<00:00, 25.27it/s]\n",
      "Test loss at 37 batch 781: 1.2909920810130668: 100%|██████████| 782/782 [00:28<00:00, 27.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:44:06+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 38 batch 3125: 1.2755129479507994: 100%|██████████| 3126/3126 [02:03<00:00, 25.28it/s]\n",
      "Test loss at 38 batch 781: 1.2784718705167564: 100%|██████████| 782/782 [00:29<00:00, 26.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:46:38+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 39 batch 3125: 1.2632629001030038: 100%|██████████| 3126/3126 [02:03<00:00, 25.37it/s]\n",
      "Test loss at 39 batch 781: 1.266560028795995: 100%|██████████| 782/782 [00:29<00:00, 26.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:49:11+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 40 batch 3125: 1.2516609459858106: 100%|██████████| 3126/3126 [02:04<00:00, 25.17it/s]\n",
      "Test loss at 40 batch 781: 1.255208679390441: 100%|██████████| 782/782 [00:27<00:00, 28.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:51:42+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 41 batch 3125: 1.2405316484100262: 100%|██████████| 3126/3126 [02:02<00:00, 25.47it/s]\n",
      "Test loss at 41 batch 781: 1.2443802828685229: 100%|██████████| 782/782 [00:29<00:00, 26.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:54:14+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 42 batch 3125: 1.2299406067761591: 100%|██████████| 3126/3126 [02:04<00:00, 25.12it/s]\n",
      "Test loss at 42 batch 781: 1.2340370471450104: 100%|██████████| 782/782 [00:28<00:00, 27.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:56:47+0000 INFO Metrics logged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss at 43 batch 3125: 1.219784085080385: 100%|██████████| 3126/3126 [02:01<00:00, 25.69it/s] \n",
      "Test loss at 43 batch 781: 1.224152172966783: 100%|██████████| 782/782 [00:27<00:00, 28.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlfoundry] 2022-07-06T16:59:16+0000 INFO Metrics logged successfully\n",
      "Stopping Training. Last\n",
      "[mlfoundry] 2022-07-06T16:59:25+0000 INFO Model logged successfully\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MlFoundryRun' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42522/3573169001.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_42522/4075293351.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(nfactor, learning_rate, weight_decay)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mlast_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pytorch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MlFoundryRun' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "for factor in factors:\n",
    "    train(nfactor=factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e892a55b-9692-48d4-8808-ad7db158b969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a147b5d-9379-4f4b-86f9-684b4c843c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
